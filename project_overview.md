# SAM 3 æ·±åº¦æŠ€æœ¯åˆ†æ

## ä¸€ã€æ•´ä½“æ¶æ„æ¦‚è§ˆ

SAM 3 é‡‡ç”¨äº†**è§£è€¦çš„æ£€æµ‹å™¨-è·Ÿè¸ªå™¨(Detector-Tracker)**åŒç»„ä»¶è®¾è®¡ï¼Œå…±äº«è§†è§‰ç¼–ç å™¨ã€‚è¿™æ˜¯ä¸€ä¸ªé©å‘½æ€§çš„æ¶æ„ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŒæ—¶å¤„ç†å›¾åƒå’Œè§†é¢‘ä»»åŠ¡ã€‚

```mermaid
graph TB
    subgraph "SAM 3 æ•´ä½“æ¶æ„"
        Input[è¾“å…¥: å›¾åƒ/è§†é¢‘ + æ–‡æœ¬/å‡ ä½•æç¤º]
        
        subgraph "å…±äº«è§†è§‰-è¯­è¨€éª¨å¹²ç½‘ç»œ"
            VisionBackbone[è§†è§‰éª¨å¹²: Dual-ViT]
            TextBackbone[æ–‡æœ¬éª¨å¹²: CLIP Text Encoder]
        end
        
        subgraph "æ£€æµ‹å™¨ Detector"
            GeomEncoder[å‡ ä½•ç¼–ç å™¨]
            TranEncoder[Transformerç¼–ç å™¨]
            TranDecoder[Transformerè§£ç å™¨]
            SegHead[åˆ†å‰²å¤´]
            PresenceToken[å­˜åœ¨æ€§Token]
        end
        
        subgraph "è·Ÿè¸ªå™¨ Tracker"
            MemoryBank[è®°å¿†åº“]
            TrackerEncoder[è·Ÿè¸ªç¼–ç å™¨]
            TrackerDecoder[è·Ÿè¸ªè§£ç å™¨]
            Association[å…³è”æ¨¡å—]
        end
        
        Output[è¾“å‡º: å®ä¾‹æ©ç  + è¾¹ç•Œæ¡† + è·Ÿè¸ªID]
    end
    
    Input --> VisionBackbone
    Input --> TextBackbone
    
    VisionBackbone --> GeomEncoder
    TextBackbone --> TranEncoder
    GeomEncoder --> TranEncoder
    
    TranEncoder --> TranDecoder
    TranDecoder --> PresenceToken
    TranDecoder --> SegHead
    
    VisionBackbone --> MemoryBank
    SegHead --> TrackerEncoder
    MemoryBank --> TrackerEncoder
    TrackerEncoder --> TrackerDecoder
    TrackerDecoder --> Association
    
    SegHead --> Output
    Association --> Output
```

## äºŒã€æ ¸å¿ƒç»„ä»¶è¯¦ç»†åˆ†æ

### 1. è§†è§‰-è¯­è¨€éª¨å¹²ç½‘ç»œ (Vision-Language Backbone)

```mermaid
graph LR
    subgraph "SAM3VLBackbone"
        IMG[å›¾åƒè¾“å…¥ HxWx3]
        TEXT[æ–‡æœ¬è¾“å…¥]
        
        subgraph "Dual-ViTè§†è§‰ç¼–ç å™¨"
            ViT1[ViT SAM3åˆ†æ”¯<br/>ç”¨äºæ£€æµ‹]
            ViT2[ViT SAM2åˆ†æ”¯<br/>ç”¨äºè·Ÿè¸ª]
            FPN[ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œ]
        end
        
        subgraph "CLIPæ–‡æœ¬ç¼–ç å™¨"
            Tokenizer[åˆ†è¯å™¨]
            TextEncoder[Transformer Text Encoder]
        end
        
        IMG --> ViT1
        IMG --> ViT2
        ViT1 --> FPN
        ViT2 --> FPN
        
        TEXT --> Tokenizer
        Tokenizer --> TextEncoder
        
        FPN --> VisionFeats[è§†è§‰ç‰¹å¾<br/>å¤šå°ºåº¦ CÃ—HÃ—W]
        FPN --> PosEnc[ä½ç½®ç¼–ç ]
        TextEncoder --> TextFeats[æ–‡æœ¬ç‰¹å¾<br/>LÃ—D]
        TextEncoder --> TextMask[æ³¨æ„åŠ›æ©ç ]
    end
```

**å…³é”®ç‰¹æ€§ï¼š**
- **Dual-ViTè®¾è®¡**ï¼šä¸¤ä¸ªç‹¬ç«‹çš„Vision Transformeråˆ†æ”¯
  - SAM3åˆ†æ”¯ï¼šä¼˜åŒ–ç”¨äºæ£€æµ‹ä»»åŠ¡
  - SAM2åˆ†æ”¯ï¼šä¼˜åŒ–ç”¨äºè·Ÿè¸ªä»»åŠ¡
- **ç‰¹å¾é‡‘å­—å¡”**ï¼šå¤šå°ºåº¦ç‰¹å¾è¡¨ç¤ºï¼Œæ•è·ä¸åŒç²’åº¦çš„è¯­ä¹‰ä¿¡æ¯
- **CLIPæ–‡æœ¬ç¼–ç å™¨**ï¼šå¤„ç†å¼€æ”¾è¯æ±‡çš„è‡ªç„¶è¯­è¨€æè¿°

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/vl_combiner.py` - SAM3VLBackboneç±»
- `sam3/model/necks.py` - Sam3DualViTDetNeckç±»
- `sam3/model/vitdet.py` - Vision Transformerå®ç°

### 2. å‡ ä½•æç¤ºç¼–ç å™¨ (Geometry Encoder)

```mermaid
graph TB
    subgraph "å‡ ä½•æç¤ºç¼–ç  Workflow"
        Prompts[å‡ ä½•æç¤ºè¾“å…¥]
        
        subgraph "æç¤ºç±»å‹"
            Points[ç‚¹æç¤º<br/>x,yåæ ‡]
            Boxes[æ¡†æç¤º<br/>x1,y1,x2,y2]
            Masks[æ©ç æç¤º<br/>äºŒå€¼æ©ç ]
        end
        
        subgraph "ç¼–ç è¿‡ç¨‹"
            PE[ä½ç½®ç¼–ç ]
            MaskEnc[æ©ç ç¼–ç å™¨<br/>å·ç§¯ç½‘ç»œ]
            Concat[æ‹¼æ¥]
        end
        
        Prompts --> Points
        Prompts --> Boxes
        Prompts --> Masks
        
        Points --> PE
        Boxes --> PE
        Masks --> MaskEnc
        
        PE --> Concat
        MaskEnc --> Concat
        
        Concat --> GeoFeats[å‡ ä½•ç‰¹å¾<br/>GÃ—D]
    end
```

**å®ç°ç»†èŠ‚ï¼ˆæ¥è‡ªä»£ç ï¼‰ï¼š**
```python
class SequenceGeometryEncoder:
    # ç¼–ç ç‚¹ã€æ¡†å’Œæ©ç æç¤º
    def forward(geo_prompt, img_feats, img_sizes, img_pos_embeds):
        # 1. å¯¹ç‚¹å’Œæ¡†ä½¿ç”¨ä½ç½®ç¼–ç 
        geo_feats = positional_encoding(points, boxes)
        
        # 2. å¯¹æ©ç ä½¿ç”¨å·ç§¯ç¼–ç å™¨
        mask_feats = mask_encoder(masks)
        
        # 3. æ‹¼æ¥æ‰€æœ‰å‡ ä½•ç‰¹å¾
        return concat([geo_feats, mask_feats])
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/geometry_encoders.py` - Promptç±»å’Œç¼–ç å™¨å®ç°

### 3. Transformerç¼–ç å™¨-è§£ç å™¨æ¶æ„

```mermaid
graph TB
    subgraph "Transformerç¼–ç è§£ç æµç¨‹"
        Input[å¤šæ¨¡æ€è¾“å…¥]
        
        subgraph "ç¼–ç å™¨ Encoder"
            ImgFeat[å›¾åƒç‰¹å¾]
            TextFeat[æ–‡æœ¬ç‰¹å¾]
            GeoFeat[å‡ ä½•ç‰¹å¾]
            
            SelfAttn1[è‡ªæ³¨æ„åŠ›]
            CrossAttn1[å›¾åƒ-æ–‡æœ¬äº¤å‰æ³¨æ„åŠ›]
            FFN1[å‰é¦ˆç½‘ç»œ]
            
            ImgFeat --> SelfAttn1
            TextFeat --> CrossAttn1
            GeoFeat --> CrossAttn1
            SelfAttn1 --> CrossAttn1
            CrossAttn1 --> FFN1
        end
        
        subgraph "è§£ç å™¨ Decoder"
            Queries[å¯¹è±¡æŸ¥è¯¢ Qä¸ª]
            Memory[ç¼–ç å™¨è®°å¿†]
            
            SelfAttn2[è‡ªæ³¨æ„åŠ›]
            CrossAttn2[æŸ¥è¯¢-ç‰¹å¾äº¤å‰æ³¨æ„åŠ›]
            FFN2[å‰é¦ˆç½‘ç»œ]
            
            RefineBox[æ¡†ç»†åŒ–]
            PresenceHead[å­˜åœ¨æ€§é¢„æµ‹å¤´]
            
            Queries --> SelfAttn2
            SelfAttn2 --> CrossAttn2
            Memory --> CrossAttn2
            CrossAttn2 --> FFN2
            
            FFN2 --> RefineBox
            FFN2 --> PresenceHead
        end
        
        subgraph "è¾“å‡º"
            Boxes[è¾¹ç•Œæ¡†]
            Scores[åˆ†ç±»åˆ†æ•°]
            Presence[å­˜åœ¨æ€§åˆ†æ•°]
            QueryEmbed[æŸ¥è¯¢åµŒå…¥]
        end
        
        Input --> ImgFeat
        Input --> TextFeat
        Input --> GeoFeat
        
        FFN1 --> Memory
        RefineBox --> Boxes
        PresenceHead --> Presence
        FFN2 --> Scores
        FFN2 --> QueryEmbed
    end
```

**å…³é”®åˆ›æ–° - å­˜åœ¨æ€§Token (Presence Token)ï¼š**
```python
# å­˜åœ¨æ€§Tokenå¸®åŠ©åŒºåˆ†ç›¸ä¼¼æç¤º
# ä¾‹å¦‚ï¼š"ç™½è¡£çƒå‘˜" vs "çº¢è¡£çƒå‘˜"

def compute_final_score(class_score, presence_score):
    # è”åˆåˆ†æ•° = åˆ†ç±»åˆ†æ•° Ã— å­˜åœ¨æ€§åˆ†æ•°
    return class_score.sigmoid() * presence_score.sigmoid()
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/encoder.py` - TransformerEncoderå’ŒTransformerEncoderLayer
- `sam3/model/sam3_image.py` - Sam3Imageç±»ï¼ŒåŒ…å«ç¼–ç è§£ç é€»è¾‘

### 4. åˆ†å‰²å¤´ (Segmentation Head)

```mermaid
graph LR
    subgraph "åˆ†å‰²å¤´æ¶æ„"
        QueryEmbed[æŸ¥è¯¢åµŒå…¥<br/>QÃ—D]
        PixelFeat[åƒç´ çº§ç‰¹å¾<br/>CÃ—HÃ—W]
        
        subgraph "æ©ç é¢„æµ‹å™¨"
            MLP1[MLPæŠ•å½±]
            PixelDec[åƒç´ è§£ç å™¨]
            DotProd[ç‚¹ç§¯]
        end
        
        QueryEmbed --> MLP1
        PixelFeat --> PixelDec
        MLP1 --> DotProd
        PixelDec --> DotProd
        
        DotProd --> Masks[å®ä¾‹æ©ç <br/>QÃ—HÃ—W]
    end
```

**å¤šæ©ç è¾“å‡ºæœºåˆ¶ï¼š**
- å¯¹äºæ¨¡ç³Šçš„æç¤ºï¼Œæ¨¡å‹è¾“å‡ºå¤šä¸ªå€™é€‰æ©ç 
- ä½¿ç”¨IoUé¢„æµ‹å¤´å¯¹æ©ç è´¨é‡è¯„åˆ†
- è®­ç»ƒæ—¶ä½¿ç”¨æœ€ä½³åŒ¹é…ï¼Œæ¨ç†æ—¶è¾“å‡ºtop-kæ©ç 

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/maskformer_segmentation.py` - SegmentationHeadå’ŒMaskPredictor

### 5. è§†é¢‘è·Ÿè¸ªå™¨ (Video Tracker)

```mermaid
graph TB
    subgraph "è§†é¢‘è·Ÿè¸ªæµç¨‹"
        Detection[æ£€æµ‹å™¨è¾“å‡º<br/>æ¯å¸§çš„æ£€æµ‹ç»“æœ]
        
        subgraph "è®°å¿†ç®¡ç†"
            MemBank[è®°å¿†åº“<br/>å­˜å‚¨å†å²ä¿¡æ¯]
            Masklet[Masklet<br/>è½¨è¿¹ç‰‡æ®µ]
            ConfStatus[ç¡®è®¤çŠ¶æ€<br/>UNCONFIRMED/CONFIRMED]
        end
        
        subgraph "å…³è”æ¨¡å—"
            IoUMatch[IoUåŒ¹é…]
            Hungarian[åŒˆç‰™åˆ©ç®—æ³•]
            ScoreThresh[åˆ†æ•°é˜ˆå€¼]
        end
        
        subgraph "è½¨è¿¹ç®¡ç†"
            NewTrack[åˆ›å»ºæ–°è½¨è¿¹]
            UpdateTrack[æ›´æ–°ç°æœ‰è½¨è¿¹]
            DeleteTrack[åˆ é™¤è½¨è¿¹]
            KeepAlive[ä¿æ´»è®¡æ•°å™¨]
        end
        
        Detection --> IoUMatch
        MemBank --> IoUMatch
        IoUMatch --> Hungarian
        Hungarian --> ScoreThresh
        
        ScoreThresh --> NewTrack
        ScoreThresh --> UpdateTrack
        ScoreThresh --> DeleteTrack
        
        NewTrack --> Masklet
        UpdateTrack --> Masklet
        Masklet --> ConfStatus
        ConfStatus --> MemBank
        
        KeepAlive --> DeleteTrack
    end
```

**è·Ÿè¸ªå…³é”®æœºåˆ¶ï¼š**

1. **Maskletç¡®è®¤æœºåˆ¶**ï¼š
```python
class MaskletConfirmationStatus:
    UNCONFIRMED = 1  # æ–°æ·»åŠ çš„è½¨è¿¹ï¼Œæœªè¢«æ£€æµ‹ç¡®è®¤
    CONFIRMED = 2     # è‡³å°‘è¢«ä¸€æ¬¡æ£€æµ‹ç¡®è®¤

# è¿ç»­3å¸§è¢«æ£€æµ‹åŒ¹é…åï¼Œè½¨è¿¹å˜ä¸ºCONFIRMEDçŠ¶æ€
if consecutive_matches >= 3:
    masklet.status = CONFIRMED
```

2. **ä¿æ´»æœºåˆ¶ (Keep-Alive)**ï¼š
```python
# æ¯ä¸ªè½¨è¿¹æœ‰ä¸€ä¸ªä¿æ´»è®¡æ•°å™¨
keep_alive_counter = init_trk_keep_alive  # åˆå§‹å€¼
max_keep_alive = 8                        # æœ€å¤§å€¼
min_keep_alive = -4                       # æœ€å°å€¼

# åŒ¹é…åˆ°æ£€æµ‹æ—¶å¢åŠ 
if matched:
    keep_alive_counter = min(keep_alive_counter + 1, max_keep_alive)
else:
    keep_alive_counter -= 1

# è®¡æ•°å™¨é™è‡³æœ€å°å€¼æ—¶åˆ é™¤è½¨è¿¹
if keep_alive_counter < min_keep_alive:
    delete_track()
```

3. **çƒ­å¯åŠ¨ (Hotstart) æœºåˆ¶**ï¼š
```python
# å»¶è¿Ÿè¾“å‡ºå‰Nå¸§ï¼Œç”¨äºè¿‡æ»¤è¯¯æ£€
hotstart_delay = 3  # å»¶è¿Ÿ3å¸§

# åœ¨çƒ­å¯åŠ¨æœŸé—´ï¼š
# 1. ç§»é™¤æœªåŒ¹é…çš„è½¨è¿¹
# 2. ç§»é™¤é‡å¤çš„è½¨è¿¹ï¼ˆIoUè¿‡é«˜ï¼‰
if frame_idx < hotstart_delay:
    filter_unmatched_tracks()
    filter_duplicate_tracks()
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/sam3_video_base.py` - Sam3VideoBaseåŸºç±»
- `sam3/model/sam3_video_inference.py` - Sam3VideoInferenceæ¨ç†ç±»
- `sam3/model/sam3_video_predictor.py` - Sam3VideoPredictoré¢„æµ‹å™¨

## ä¸‰ã€è®­ç»ƒæµç¨‹

```mermaid
graph TB
    subgraph "SAM 3 è®­ç»ƒPipeline"
        Data[è®­ç»ƒæ•°æ®]
        
        subgraph "æ•°æ®åŠ è½½"
            COCO[COCOæ ¼å¼æ•°æ®é›†]
            Collator[æ•°æ®æ•´ç†å™¨]
            Transform[æ•°æ®å¢å¼º]
        end
        
        subgraph "å‰å‘ä¼ æ’­"
            Model[SAM3æ¨¡å‹]
            Pred[é¢„æµ‹è¾“å‡º]
        end
        
        subgraph "æŸå¤±è®¡ç®—"
            Matcher[åŒˆç‰™åˆ©åŒ¹é…å™¨]
            
            subgraph "æŸå¤±å‡½æ•°"
                FocalLoss[Focal Loss<br/>åˆ†ç±»]
                DiceLoss[Dice Loss<br/>æ©ç ]
                IoULoss[IoU Loss<br/>æ¡†]
                PresenceLoss[Presence Loss<br/>å­˜åœ¨æ€§]
            end
            
            TotalLoss[åŠ æƒæ€»æŸå¤±]
        end
        
        subgraph "åå‘ä¼ æ’­"
            Optimizer[AdamWä¼˜åŒ–å™¨]
            Scheduler[å­¦ä¹ ç‡è°ƒåº¦å™¨]
            GradClip[æ¢¯åº¦è£å‰ª]
        end
        
        Data --> COCO
        COCO --> Transform
        Transform --> Collator
        Collator --> Model
        Model --> Pred
        
        Pred --> Matcher
        Matcher --> FocalLoss
        Matcher --> DiceLoss
        Matcher --> IoULoss
        Matcher --> PresenceLoss
        
        FocalLoss --> TotalLoss
        DiceLoss --> TotalLoss
        IoULoss --> TotalLoss
        PresenceLoss --> TotalLoss
        
        TotalLoss --> GradClip
        GradClip --> Optimizer
        Optimizer --> Scheduler
    end
```

**æŸå¤±å‡½æ•°æƒé‡é…ç½®ï¼š**
```python
weight_dict = {
    'loss_ce': 2.0,        # åˆ†ç±»æŸå¤±
    'loss_bbox': 5.0,      # æ¡†L1æŸå¤±  
    'loss_giou': 2.0,      # æ¡†GIoUæŸå¤±
    'loss_mask': 5.0,      # æ©ç æŸå¤±
    'loss_dice': 5.0,      # DiceæŸå¤±
    'loss_presence': 1.0,  # å­˜åœ¨æ€§æŸå¤±
}
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/train/trainer.py` - Trainerè®­ç»ƒç±»
- `sam3/train/loss/loss_fns.py` - æŸå¤±å‡½æ•°å®ç°
- `sam3/train/matcher.py` - åŒˆç‰™åˆ©åŒ¹é…å™¨
- `sam3/train/optim/optimizer.py` - ä¼˜åŒ–å™¨é…ç½®

## å››ã€æ¨ç†æµç¨‹

```mermaid
graph TB
    subgraph "SAM 3 æ¨ç†æµç¨‹"
        Input[è¾“å…¥]
        
        subgraph "å›¾åƒæ¨ç†"
            ImgInput[å›¾åƒ + æç¤º]
            ImgProc[å›¾åƒå¤„ç†å™¨]
            Detection[æ£€æµ‹è¾“å‡º]
            NMS[éæå¤§å€¼æŠ‘åˆ¶]
            ImgResult[æ©ç  + æ¡† + åˆ†æ•°]
        end
        
        subgraph "è§†é¢‘æ¨ç†"
            VidInput[è§†é¢‘ + æç¤º]
            SessionMgr[ä¼šè¯ç®¡ç†å™¨]
            
            subgraph "é€å¸§å¤„ç†"
                FrameProc[å¸§å¤„ç†]
                DetTrack[æ£€æµ‹+è·Ÿè¸ª]
                Assoc[å…³è”åŒ¹é…]
                MemUpdate[è®°å¿†æ›´æ–°]
            end
            
            VidResult[å¸¦è·Ÿè¸ªIDçš„æ©ç åºåˆ—]
        end
        
        Input --> ImgInput
        Input --> VidInput
        
        ImgInput --> ImgProc
        ImgProc --> Detection
        Detection --> NMS
        NMS --> ImgResult
        
        VidInput --> SessionMgr
        SessionMgr --> FrameProc
        FrameProc --> DetTrack
        DetTrack --> Assoc
        Assoc --> MemUpdate
        MemUpdate --> FrameProc
        MemUpdate --> VidResult
    end
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/model/sam3_image_processor.py` - Sam3Processorå›¾åƒå¤„ç†å™¨
- `sam3/model/sam3_video_predictor.py` - Sam3VideoPredictorè§†é¢‘é¢„æµ‹å™¨
- `sam3/model_builder.py` - æ¨¡å‹æ„å»ºå‡½æ•°

## äº”ã€å…³é”®æŠ€æœ¯åˆ›æ–°

### 1. å­˜åœ¨æ€§Token (Presence Token)

**é—®é¢˜ï¼š** ä¼ ç»Ÿæ¨¡å‹éš¾ä»¥åŒºåˆ†"ç™½è¡£çƒå‘˜"å’Œ"çº¢è¡£çƒå‘˜"è¿™æ ·çš„ç›¸ä¼¼æç¤º

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# è§£ç å™¨è¾“å‡ºä¸¤ä¸ªåˆ†æ”¯
class_logits = dot_product(query_embed, text_embed)  # åˆ†ç±»åˆ†æ•°
presence_logits = presence_head(query_embed)          # å­˜åœ¨æ€§åˆ†æ•°

# æœ€ç»ˆåˆ†æ•° = ä¸¤è€…çš„ä¹˜ç§¯
final_score = class_logits.sigmoid() * presence_logits.sigmoid()
```

**æ•ˆæœï¼š** åœ¨SA-Co/Goldä¸Šæå‡~5ä¸ªç™¾åˆ†ç‚¹

### 2. è§£è€¦çš„æ£€æµ‹å™¨-è·Ÿè¸ªå™¨

**ä¼˜åŠ¿ï¼š**
- æ£€æµ‹å™¨ä¸“æ³¨äºæ¯å¸§çš„ç›®æ ‡æ£€æµ‹
- è·Ÿè¸ªå™¨ä¸“æ³¨äºè·¨å¸§çš„èº«ä»½å…³è”
- é¿å…ä»»åŠ¡å¹²æ‰°ï¼Œæå‡æ€§èƒ½

### 3. æ•°æ®å¼•æ“

**åˆ›æ–°ï¼š**
- è‡ªåŠ¨æ ‡æ³¨äº†400ä¸‡+ç‹¬ç‰¹æ¦‚å¿µ
- ä½¿ç”¨SAMæ¨¡å‹è¿›è¡Œè‡ªåŠ¨åˆ†å‰²
- äººå·¥éªŒè¯è´¨é‡æ§åˆ¶
- åˆ›å»ºäº†æœ€å¤§çš„å¼€æ”¾è¯æ±‡åˆ†å‰²æ•°æ®é›†

### 4. æ€§èƒ½ä¼˜åŒ–

**Tritonå†…æ ¸ä¼˜åŒ–ï¼š**
```python
@triton.jit
def sigmoid_focal_loss_kernel(
    inputs_ptr, targets_ptr, output_ptr,
    alpha, gamma, BLOCK_SIZE
):
    # è‡ªå®šä¹‰CUDAå†…æ ¸ï¼ŒåŠ é€ŸFocal Lossè®¡ç®—
    # æ¯”PyTorchåŸç”Ÿå®ç°å¿«3-5å€
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/train/loss/sigmoid_focal_loss.py` - Tritonä¼˜åŒ–çš„Focal Loss
- `sam3/perflib/triton/connected_components.py` - è¿é€šç»„ä»¶è®¡ç®—ä¼˜åŒ–

## å…­ã€è¯„ä¼°æŒ‡æ ‡

### 1. cgF1 (Concept-Grounded F1)

```python
# è®¡ç®—å…¬å¼
Precision = TP / (TP + FP)
Recall = TP / (TP + FN)
cgF1 = 2 * (Precision * Recall) / (Precision + Recall)

# ç‰¹ç‚¹ï¼šè€ƒè™‘æ¦‚å¿µçº§åˆ«çš„åŒ¹é…
# ä¸€ä¸ªæç¤ºçš„æ‰€æœ‰å®ä¾‹å¿…é¡»éƒ½æ­£ç¡®æ‰ç®—TP
```

#### ğŸ“– Precisionå’ŒRecallè¯¦ç»†è§£é‡Š

**åŸºç¡€æœ¯è¯­å®šä¹‰ï¼š**
```
TP (True Positive)  - çœŸé˜³æ€§ï¼šé¢„æµ‹ä¸ºæ­£ä¸”å®é™…ä¸ºæ­£ âœ“
FP (False Positive) - å‡é˜³æ€§ï¼šé¢„æµ‹ä¸ºæ­£ä½†å®é™…ä¸ºè´Ÿ âœ—
TN (True Negative)  - çœŸé˜´æ€§ï¼šé¢„æµ‹ä¸ºè´Ÿä¸”å®é™…ä¸ºè´Ÿ âœ“
FN (False Negative) - å‡é˜´æ€§ï¼šé¢„æµ‹ä¸ºè´Ÿä½†å®é™…ä¸ºæ­£ âœ—
```

**Precisionï¼ˆå‡†ç¡®åº¦/ç²¾ç¡®ç‡ï¼‰ï¼š**
```python
Precision = TP / (TP + FP)
          = é¢„æµ‹æ­£ç¡®çš„æ­£æ ·æœ¬æ•° / æ‰€æœ‰é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬æ•°
```

**å«ä¹‰ï¼š** "åœ¨æ‰€æœ‰æˆ‘é¢„æµ‹å‡ºæ¥çš„å¯¹è±¡ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸçš„å¯¹çš„ï¼Ÿ"

**ä¾‹å­ï¼š** æç¤º"æ‰¾å‡ºå›¾ä¸­æ‰€æœ‰çš„ç‹—"
```python
# åœºæ™¯ï¼šå›¾ä¸­çœŸå®æœ‰3åªç‹—
Ground Truth: 3åªç‹—

# æ¨¡å‹é¢„æµ‹å‡º5ä¸ªå¯¹è±¡æ˜¯ç‹—
Predictions: 5ä¸ªå¯¹è±¡

# åˆ†æï¼š
TP = 3  # æ­£ç¡®è¯†åˆ«çš„ç‹—
FP = 2  # è¯¯æ£€ï¼ˆæŠŠçŒ«å½“æˆç‹—ï¼‰

Precision = 3 / (3 + 2) = 60%
# è§£è¯»ï¼šé¢„æµ‹çš„5ä¸ªå¯¹è±¡ä¸­ï¼Œåªæœ‰60%çœŸçš„æ˜¯ç‹—
```

**Recallï¼ˆå¬å›ç‡/æŸ¥å…¨ç‡ï¼‰ï¼š**
```python
Recall = TP / (TP + FN)
       = é¢„æµ‹æ­£ç¡®çš„æ­£æ ·æœ¬æ•° / å®é™…å­˜åœ¨çš„æ­£æ ·æœ¬æ€»æ•°
```

**å…³é”®ç†è§£ - åˆ†æ¯å«ä¹‰ï¼š**
- `TP + FN` = æ‰€æœ‰çœŸå®å­˜åœ¨çš„æ­£æ ·æœ¬æ€»æ•°ï¼ˆGround Truthï¼‰
- `TP`ï¼šçœŸå®å­˜åœ¨ä¸”è¢«æ‰¾åˆ°çš„
- `FN`ï¼šçœŸå®å­˜åœ¨ä½†æœªè¢«æ‰¾åˆ°çš„ï¼ˆæ¼æ£€ï¼‰

**å«ä¹‰ï¼š** "åœ¨æ‰€æœ‰çœŸå®å­˜åœ¨çš„å¯¹è±¡ä¸­ï¼Œæˆ‘æ‰¾åˆ°äº†å¤šå°‘ï¼Ÿ"

**ä¾‹å­ï¼š** ç»§ç»­ä¸Šé¢çš„åœºæ™¯
```python
# åœºæ™¯ï¼šå›¾ä¸­çœŸå®æœ‰5åªç‹—
Ground Truth: 5åªç‹—

# æ¨¡å‹åªé¢„æµ‹å‡º3ä¸ªå¯¹è±¡æ˜¯ç‹—
Predictions: 3ä¸ªå¯¹è±¡

# åˆ†æï¼š
TP = 3  # æ­£ç¡®æ‰¾åˆ°3åªç‹—
FP = 0  # æ²¡æœ‰è¯¯æ£€
FN = 2  # æ¼æ£€2åªç‹—ï¼ˆçœŸå®å­˜åœ¨ä½†æœªæ‰¾åˆ°ï¼‰

Recall = 3 / (3 + 2) = 60%
# è§£è¯»ï¼š5åªçœŸå®çš„ç‹—ä¸­ï¼Œåªæ‰¾åˆ°äº†60%
```

**Precision vs Recallæƒè¡¡ï¼š**
```
é«˜é˜ˆå€¼ï¼ˆä¸¥æ ¼ï¼‰â†’ é«˜Precisionï¼ˆé¢„æµ‹çš„å‡†ï¼‰+ ä½Recallï¼ˆæ‰¾å¾—å°‘ï¼‰
ä½é˜ˆå€¼ï¼ˆå®½æ¾ï¼‰â†’ ä½Precisionï¼ˆè¯¯æ£€å¤šï¼‰  + é«˜Recallï¼ˆæ‰¾å¾—å…¨ï¼‰
```

**å®Œæ•´ç¤ºä¾‹ï¼š**
```python
# åœºæ™¯ï¼šå›¾ä¸­æœ‰10åªçœŸå®çš„ç‹—
Ground Truth: 10åªç‹—

# æ¨¡å‹é¢„æµ‹å‡º12ä¸ªå¯¹è±¡
Predictions: 12ä¸ªå¯¹è±¡

# ç»“æœï¼š
TP = 8   # æ­£ç¡®æ‰¾åˆ°8åªç‹—
FP = 4   # è¯¯æ£€4ä¸ªï¼ˆä¸æ˜¯ç‹—ï¼‰
FN = 2   # æ¼æ£€2åªç‹—

# è®¡ç®—ï¼š
Precision = 8/(8+4) = 8/12 = 66.7%  # é¢„æµ‹å‡†ç¡®åº¦
Recall = 8/(8+2) = 8/10 = 80.0%     # å¬å›å®Œæ•´åº¦
F1 = 2Ã—(0.667Ã—0.8)/(0.667+0.8) = 72.7%  # ç»¼åˆè¯„åˆ†
```

**è®°å¿†æŠ€å·§ï¼š**
- **Precisionå…³æ³¨"è´¨é‡"**ï¼šæˆ‘è¯´çš„æœ‰å¤šå‡†ï¼Ÿï¼ˆåˆ†æ¯=æˆ‘é¢„æµ‹çš„æ€»æ•°ï¼‰
- **Recallå…³æ³¨"è¦†ç›–"**ï¼šæˆ‘æ‰¾å…¨äº†å—ï¼Ÿï¼ˆåˆ†æ¯=çœŸå®å­˜åœ¨çš„æ€»æ•°ï¼‰

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/eval/cgf1_eval.py` - CGF1Evalå’ŒCGF1Evaluatorç±»

### 2. pHOTA (Phrase HOTA)

ç”¨äºè§†é¢‘è¯„ä¼°ï¼Œç»“åˆæ£€æµ‹å‡†ç¡®ç‡å’Œè·Ÿè¸ªä¸€è‡´æ€§ï¼š

```python
HOTA = sqrt(DetA * AssA)
DetA = Detection Accuracy  # æ£€æµ‹å‡†ç¡®ç‡
AssA = Association Accuracy  # å…³è”å‡†ç¡®ç‡
```

**ä»£ç å®ç°ä½ç½®ï¼š**
- `sam3/eval/hota_eval_toolkit/` - HOTAè¯„ä¼°å·¥å…·åŒ…
- `sam3/eval/teta_eval_toolkit/` - TETAè¯„ä¼°å·¥å…·åŒ…

## ä¸ƒã€å®é™…åº”ç”¨ç¤ºä¾‹

### å›¾åƒåˆ†å‰²ç¤ºä¾‹ä»£ç ï¼š

```python
from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor

# åŠ è½½æ¨¡å‹
model = build_sam3_image_model()
processor = Sam3Processor(model)

# å¤„ç†å›¾åƒ
image = Image.open("example.jpg")
inference_state = processor.set_image(image)

# æ–‡æœ¬æç¤º
output = processor.set_text_prompt(
    state=inference_state, 
    prompt="person wearing red shirt"
)

# è·å–ç»“æœ
masks = output["masks"]        # å®ä¾‹æ©ç 
boxes = output["boxes"]        # è¾¹ç•Œæ¡†  
scores = output["scores"]      # ç½®ä¿¡åº¦åˆ†æ•°
```

### è§†é¢‘è·Ÿè¸ªç¤ºä¾‹ä»£ç ï¼š

```python
from sam3.model_builder import build_sam3_video_predictor

# åŠ è½½è§†é¢‘é¢„æµ‹å™¨
video_predictor = build_sam3_video_predictor()

# åˆ›å»ºä¼šè¯
response = video_predictor.handle_request({
    "type": "start_session",
    "resource_path": "video.mp4"
})

session_id = response["session_id"]

# æ·»åŠ æç¤ºï¼ˆåœ¨ç¬¬0å¸§ï¼‰
response = video_predictor.handle_request({
    "type": "add_prompt",
    "session_id": session_id,
    "frame_index": 0,
    "text": "person in blue jacket"
})

# è·å–æ‰€æœ‰å¸§çš„è·Ÿè¸ªç»“æœ
outputs = response["outputs"]
# outputsåŒ…å«æ¯å¸§çš„æ©ç ã€æ¡†å’Œè·Ÿè¸ªID
```

## å…«ã€é¡¹ç›®ç»“æ„

```
sam3/
â”œâ”€â”€ model/                      # æ ¸å¿ƒæ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ sam3_image.py          # å›¾åƒåˆ†å‰²æ¨¡å‹
â”‚   â”œâ”€â”€ sam3_video_base.py     # è§†é¢‘è·Ÿè¸ªåŸºç±»
â”‚   â”œâ”€â”€ sam3_video_inference.py # è§†é¢‘æ¨ç†å®ç°
â”‚   â”œâ”€â”€ vl_combiner.py         # è§†è§‰-è¯­è¨€éª¨å¹²
â”‚   â”œâ”€â”€ vitdet.py              # Vision Transformer
â”‚   â”œâ”€â”€ encoder.py             # Transformerç¼–ç å™¨
â”‚   â”œâ”€â”€ geometry_encoders.py   # å‡ ä½•æç¤ºç¼–ç å™¨
â”‚   â”œâ”€â”€ maskformer_segmentation.py # åˆ†å‰²å¤´
â”‚   â””â”€â”€ box_ops.py             # è¾¹ç•Œæ¡†æ“ä½œ
â”‚
â”œâ”€â”€ train/                      # è®­ç»ƒåŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ trainer.py             # è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ data/                  # æ•°æ®åŠ è½½
â”‚   â”‚   â”œâ”€â”€ sam3_image_dataset.py
â”‚   â”‚   â”œâ”€â”€ sam3_video_dataset.py
â”‚   â”‚   â””â”€â”€ collator.py
â”‚   â”œâ”€â”€ loss/                  # æŸå¤±å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ loss_fns.py
â”‚   â”‚   â””â”€â”€ sigmoid_focal_loss.py
â”‚   â”œâ”€â”€ optim/                 # ä¼˜åŒ–å™¨
â”‚   â””â”€â”€ transforms/            # æ•°æ®å¢å¼º
â”‚
â”œâ”€â”€ eval/                       # è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ cgf1_eval.py           # cgF1æŒ‡æ ‡
â”‚   â”œâ”€â”€ hota_eval_toolkit/     # HOTAè¯„ä¼°
â”‚   â”œâ”€â”€ teta_eval_toolkit/     # TETAè¯„ä¼°
â”‚   â””â”€â”€ coco_eval.py           # COCOè¯„ä¼°
â”‚
â”œâ”€â”€ perflib/                    # æ€§èƒ½ä¼˜åŒ–
â”‚   â””â”€â”€ triton/                # Tritonå†…æ ¸
â”‚
â””â”€â”€ agent/                      # SAM 3 Agent
    â””â”€â”€ helpers/               # è¾…åŠ©å‡½æ•°
```

## ä¹ã€æ€§èƒ½åŸºå‡†

### å›¾åƒåˆ†å‰²æ€§èƒ½

| æ¨¡å‹ | LVIS cgF1 | LVIS AP | SA-Co/Gold cgF1 | COCO AP |
|------|-----------|---------|-----------------|---------|
| äººç±» | - | - | **72.8** | - |
| OWLv2 | 29.3 | 43.4 | 24.6 | 46.1 |
| DINO-X | - | 38.5 | 21.3 | 56.0 |
| Gemini 2.5 | 13.4 | - | 13.0 | - |
| **SAM 3** | **37.2** | **48.5** | **54.1** | **56.4** |

### è§†é¢‘è·Ÿè¸ªæ€§èƒ½

| æ¨¡å‹ | SA-V cgF1 | YT-Temporal cgF1 | SmartGlasses cgF1 | LVVIS mAP | BURST HOTA |
|------|-----------|------------------|-------------------|-----------|------------|
| äººç±» | **53.1** | **71.2** | **58.5** | - | - |
| **SAM 3** | **30.3** | **50.8** | **36.4** | **36.3** | **44.5** |

**ç›¸å¯¹äººç±»æ€§èƒ½ï¼š**
- å›¾åƒï¼š74-75%
- è§†é¢‘ï¼š57-71%

## åã€æ•°æ®é›†

### SA-Co åŸºå‡†æ•°æ®é›†

SAM 3 å‘å¸ƒäº†ä¸‰ä¸ªæ–°çš„è¯„ä¼°åŸºå‡†ï¼š

1. **SA-Co/Gold** - é«˜è´¨é‡å›¾åƒæ ‡æ³¨
   - ç²¾å¿ƒæ ‡æ³¨çš„å›¾åƒæ•°æ®é›†
   - 270K+ç‹¬ç‰¹æ¦‚å¿µ
   - HuggingFace: `facebook/SACo-Gold`

2. **SA-Co/Silver** - å¤§è§„æ¨¡å›¾åƒæ•°æ®é›†
   - æ›´å¤§è§„æ¨¡çš„æ ‡æ³¨æ•°æ®
   - ç”¨äºè®­ç»ƒå’Œè¯„ä¼°
   - HuggingFace: `facebook/SACo-Silver`

3. **SA-Co/VEval** - è§†é¢‘è·Ÿè¸ªåŸºå‡†
   - è§†é¢‘çº§åˆ«çš„æ ‡æ³¨
   - è·¨å¸§è·Ÿè¸ªè¯„ä¼°
   - HuggingFace: `facebook/SACo-VEval`

**æ•°æ®æ ¼å¼ï¼š** COCOæ ¼å¼çš„JSONæ ‡æ³¨

## åä¸€ã€ä¾èµ–é¡¹

### æ ¸å¿ƒä¾èµ–

```python
# pyproject.toml
dependencies = [
    "torch>=2.7.0",              # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
    "torchvision",               # è§†è§‰å·¥å…·
    "timm>=1.0.17",              # Vision Transformeræ¨¡å‹
    "numpy>=1.26,<2",            # æ•°å€¼è®¡ç®—
    "huggingface_hub",           # æ¨¡å‹ä¸‹è½½
    "ftfy==6.1.1",               # æ–‡æœ¬ä¿®å¤
    "regex",                     # æ­£åˆ™è¡¨è¾¾å¼
    "iopath>=0.1.10",            # æ–‡ä»¶IO
]
```

### è®­ç»ƒä¾èµ–

```python
train = [
    "hydra-core",                # é…ç½®ç®¡ç†
    "submitit",                  # SLURMä½œä¸šæäº¤
    "tensorboard",               # å¯è§†åŒ–
    "scipy",                     # ç§‘å­¦è®¡ç®—
    "torchmetrics",              # æŒ‡æ ‡è®¡ç®—
    "fvcore",                    # Facebookè§†è§‰æ ¸å¿ƒåº“
    "fairscale",                 # åˆ†å¸ƒå¼è®­ç»ƒ
]
```

## åäºŒã€å®‰è£…æŒ‡å—

### åŸºç¡€å®‰è£…

```bash
# 1. åˆ›å»ºCondaç¯å¢ƒ
conda create -n sam3 python=3.12
conda activate sam3

# 2. å®‰è£…PyTorch (CUDA 12.6)
pip install torch==2.7.0 torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu126

# 3. å…‹éš†å¹¶å®‰è£…SAM 3
git clone https://github.com/facebookresearch/sam3.git
cd sam3
pip install -e .

# 4. å®‰è£…é¢å¤–ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install -e ".[notebooks]"  # Jupyter notebooks
pip install -e ".[train,dev]"  # è®­ç»ƒå’Œå¼€å‘
```

### è·å–æ¨¡å‹æƒé‡

```bash
# éœ€è¦HuggingFaceè®¤è¯
huggingface-cli login

# æ¨¡å‹ä¼šè‡ªåŠ¨ä»HuggingFaceä¸‹è½½
# https://huggingface.co/facebook/sam3
```

## åä¸‰ã€è®­ç»ƒé…ç½®

### Hydraé…ç½®ç³»ç»Ÿ

SAM 3 ä½¿ç”¨Hydraè¿›è¡Œé…ç½®ç®¡ç†ï¼Œé…ç½®æ–‡ä»¶ä½äºï¼š

```
sam3/train/configs/
â”œâ”€â”€ eval_base.yaml                    # åŸºç¡€è¯„ä¼°é…ç½®
â”œâ”€â”€ gold_image_evals/                 # Goldå›¾åƒè¯„ä¼°
â”‚   â””â”€â”€ sam3_gold_image_attributes.yaml
â”œâ”€â”€ silver_image_evals/               # Silverå›¾åƒè¯„ä¼°
â”‚   â””â”€â”€ sam3_silver_image_bdd100k.yaml
â””â”€â”€ saco_video_evals/                 # è§†é¢‘è¯„ä¼°
    â””â”€â”€ saco_veval_sav_test.yaml
```

### è®­ç»ƒå‘½ä»¤ç¤ºä¾‹

```bash
# å•èŠ‚ç‚¹è®­ç»ƒ
python sam3/train/train.py \
    --config-name=your_config \
    launcher.num_nodes=1 \
    launcher.gpus_per_node=8

# å¤šèŠ‚ç‚¹SLURMè®­ç»ƒ
python sam3/train/train.py \
    --config-name=your_config \
    launcher.num_nodes=4 \
    launcher.gpus_per_node=8 \
    launcher.partition=your_partition
```

## åå››ã€è¯„ä¼°

### è¿è¡Œè¯„ä¼°

```bash
# COCOæ ¼å¼è¯„ä¼°
python scripts/eval/standalone_cgf1.py \
    --gt-json path/to/gt.json \
    --dt-json path/to/predictions.json

# è§†é¢‘è¯„ä¼°
python sam3/eval/saco_veval_eval.py \
    --gt-annot-dir path/to/annotations \
    --eval-res-dir path/to/results
```

## åäº”ã€æ€»ç»“

SAM 3 çš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **å¼€æ”¾è¯æ±‡èƒ½åŠ›**ï¼šæ”¯æŒ27ä¸‡+æ¦‚å¿µï¼Œæ˜¯ç°æœ‰åŸºå‡†çš„50å€
2. **ç»Ÿä¸€æ¶æ„**ï¼šä¸€ä¸ªæ¨¡å‹å¤„ç†å›¾åƒå’Œè§†é¢‘ä»»åŠ¡
3. **å­˜åœ¨æ€§Token**ï¼šç²¾å‡†åŒºåˆ†ç›¸ä¼¼æç¤º
4. **è§£è€¦è®¾è®¡**ï¼šæ£€æµ‹å™¨å’Œè·Ÿè¸ªå™¨ç‹¬ç«‹ä¼˜åŒ–
5. **å¤§è§„æ¨¡æ•°æ®**ï¼š400ä¸‡+æ¦‚å¿µçš„è‡ªåŠ¨æ ‡æ³¨æ•°æ®é›†
6. **é«˜æ€§èƒ½**ï¼šè¾¾åˆ°äººç±»æ€§èƒ½çš„57-75%

### åº”ç”¨åœºæ™¯

- **æ™ºèƒ½æ ‡æ³¨**ï¼šè‡ªåŠ¨åŒ–æ•°æ®æ ‡æ³¨æµç¨‹
- **è§†é¢‘åˆ†æ**ï¼šåœºæ™¯ç†è§£ã€å¯¹è±¡è·Ÿè¸ª
- **æœºå™¨äººè§†è§‰**ï¼šå¼€æ”¾ä¸–ç•Œåœºæ™¯ç†è§£
- **åŒ»ç–—å½±åƒ**ï¼šå™¨å®˜å’Œç—…ç¶åˆ†å‰²
- **è‡ªåŠ¨é©¾é©¶**ï¼šåŠ¨æ€åœºæ™¯ç†è§£
- **å¢å¼ºç°å®**ï¼šå®æ—¶å¯¹è±¡åˆ†å‰²å’Œè·Ÿè¸ª

### æœªæ¥æ–¹å‘

- æå‡æ¥è¿‘äººç±»æ°´å¹³çš„æ€§èƒ½
- æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€ï¼ˆ3Dã€å¤šå…‰è°±ç­‰ï¼‰
- ä¼˜åŒ–æ¨ç†é€Ÿåº¦å’Œå†…å­˜å ç”¨
- å¢å¼ºæ—¶åºç†è§£èƒ½åŠ›
- æ”¯æŒæ›´å¤æ‚çš„æ¨ç†ä»»åŠ¡

---

**é¡¹ç›®ä¿¡æ¯ï¼š**
- **ç‰ˆæœ¬**: 0.1.0 (Beta)
- **è®¸å¯è¯**: SAM License
- **ç»„ç»‡**: Meta Superintelligence Labs
- **è®ºæ–‡**: https://arxiv.org/abs/2511.16719
- **é¡¹ç›®ä¸»é¡µ**: https://ai.meta.com/sam3
- **GitHub**: https://github.com/facebookresearch/sam3